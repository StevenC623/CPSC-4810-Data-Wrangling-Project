{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC4810 Team Project \n",
    "#### Leo Liang\n",
    "#### Qirui Cao\n",
    "#### Latesh Subramanayam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Data Inspection and Cleaning\n",
    "\n",
    "(description data sources for each dataset:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the county data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCounty = pd.read_csv(\"data/us_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCounty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"County dataset has\", dfCounty.shape[0], \"rows and\", dfCounty.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of rows in the dataset is equal to the number of unique values in column 'fips':\", \n",
    "      len(dfCounty) == dfCounty.fips.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of rows of the dataframe is equal to the number of unique values for variable \"fips\". We can consider the column \"fips\" as the key of the dataframe. That is, each row in dataframe dfCounty represents a different US county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCounty.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, by running the total number of missing values for each variable, we find out that there are 79 missing values for \"state_code\". Then we need to check those rows containing missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCounty[dfCounty.state_code.isnull()]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puerto Rico has\", len(dfCounty[dfCounty.state == \"Puerto Rico\"]), \"rows in the dataframe. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"District of Columbia\", len(dfCounty[dfCounty.state == \"District of Columbia\"]), \"rows in the dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find out that the only two states which do not have a state code are Puerto Rico and District of Columbia. By comparing the number of rows for two states, and the number of missing value occurance, we can be sure that state Puerto Rico and District of Columbia do not have state code. \n",
    "\n",
    "This is because both areas are not a US state, then they do not have a US state code. Since Puerto Rico is not part of 50 states + 1 disctrict, we exclude those observations from the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCounty = dfCounty.drop(dfCounty[dfCounty.state == \"Puerto Rico\"].index)\n",
    "dfCounty.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCounty.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we aggregate the population by all states to replicate the raw dataframe with state-level information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_pop = pd.DataFrame(dfCounty.groupby('state')[['male','female','population']].sum())\n",
    "state_pop[\"female_proportion\"] = state_pop.female/state_pop.population\n",
    "state_pop.reset_index(level=0, inplace=True)\n",
    "state_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Poverty data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty = pd.read_csv(\"data/PovertyEstimates_us_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we altered the dataset to keep the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty = dfPoverty[['FIPStxt', 'Stabr', 'Area_name', 'Rural-urban_Continuum_Code_2013', 'Urban_Influence_Code_2013', \n",
    "                        'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018', 'MEDHHINC_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Poverty dataset has\", dfPoverty.shape[0], \"rows and\", dfPoverty.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of rows in the dataset is equal to the number of unique values in column 'fips':\", \n",
    "      len(dfPoverty) == dfPoverty[\"FIPStxt\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, since the number of rows of the dataframe is equal to the number of unique values for variable \"FIPStxt\". We can consider the column \"FIPStxt\" as the key of the dataframe. That is, each row in dataframe dfCounty represents a different US area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, by running the total number of missing values for each variable, we find out that there are 52 missing values for 2013's \"RUCC\" and \"UIC\". Then we need to check those rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty[dfPoverty[\"Rural-urban_Continuum_Code_2013\"].isna()][\"Area_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty[dfPoverty[\"Urban_Influence_Code_2013\"].isna()][\"Area_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the missing values in both columns, the corresponding area names are states and US itself. The missing values are due to the fact that the country US itself and states are not applied to the county-level code, as it only applies to counties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, Rural-urban Continuum Code 2013 and Urban Influence Code 2013 are all categorical variables, which have their corresponding categories. (Please see documents below) Then, we need to map the code to their corresponding description. \n",
    "\n",
    "Rural-Urban Continuum Code: https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/documentation/\n",
    "Urban Influence Code: https://www.ers.usda.gov/data-products/urban-influence-codes/documentation.aspx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUCC = {1: \"Level 1\", \n",
    "           2: \"Level 2\",\n",
    "           3: \"Level 3\",\n",
    "           4: \"Level 4\",\n",
    "           5: \"Level 5\",\n",
    "           6: \"Level 6\", \n",
    "           7: \"Level 7\", \n",
    "           8: \"Level 8\",\n",
    "           9: \"Level 9\"\n",
    "          }\n",
    "\n",
    "UIC = {1: \"In large metro area of 1+ million residents\",\n",
    "       2: \"In small metro area of less than 1 million residents\",\n",
    "       3: \"Micropolitan area adjacent to large metro area\",\n",
    "       4: \"Noncore adjacent to large metro area\",\n",
    "       5: \"Micropolitan area adjacent to small metro area\",\n",
    "       6: \"Noncore adjacent to small metro area and contains a town of at least 2,500 residents\",\n",
    "       7: \"Noncore adjacent to small metro area and does not contain a town of at least 2,500 residents\",\n",
    "       8: \"Micropolitan area not adjacent to a metro area\",\n",
    "       9: \"Noncore adjacent to micro area and contains a town of at least 2,500 residents\",\n",
    "       10: \"Noncore adjacent to micro area and does not contain a town of at least 2,500 residents\",\n",
    "       11: \"Noncore not adjacent to metro or micro area and contains a town of at least 2,500 residents\",\n",
    "       12: \"Noncore not adjacent to metro or micro area and does not contain a town of at least 2,500 residents\"\n",
    "      }\n",
    "\n",
    "dfPoverty[\"Rural-urban_Continuum_Code_2013\"] = dfPoverty[\"Rural-urban_Continuum_Code_2013\"].map(RUCC)\n",
    "dfPoverty[\"Urban_Influence_Code_2013\"] = dfPoverty[\"Urban_Influence_Code_2013\"].map(UIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPoverty.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect COVID case and death data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty = pd.read_csv(\"data/covid_us_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"COVID dataset has\", dfcovCnty.shape[0], \"rows and\", dfcovCnty.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data contains the county-level cumulative cases and deaths starting from January 22nd, 2020. Let's take the current date, and inspect the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current = dfcovCnty[dfcovCnty['date'] == '2021-07-30']\n",
    "dfcovCnty_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"current date COVID dataset has\", dfcovCnty_current.shape[0], \"rows and\", dfcovCnty_current.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 missing values in column \"fips\", 6 in column \"county\" and 89 in column \"state_code\". We need to check all the rows containing these missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current[dfcovCnty_current.fips.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the merging stage of our project, we will merge by fips, which is the key column for most of our county-level dataframe, we will remove those rows containing missing values in fips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current[dfcovCnty_current.county.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing values in county indicates two cruise ships and four areas outside 50 states + 1 district, we remove those rows as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty=dfcovCnty.dropna(subset=['fips','county'])\n",
    "dfcovCnty_current=dfcovCnty_current.dropna(subset=['fips','county'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we checked the rows with missing state codes, and found out that only Puerto Rico and District of Columbia don't have state code. It is the same case as the previous situation where both areas are not a US state, thus there are no state codes. And we removed rows with Puerto Rico as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current[dfcovCnty_current.state_code.isnull()].state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puerto Rico has\", len(dfcovCnty_current[dfcovCnty_current.state == \"Puerto Rico\"]), \"rows in the dataframe. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"District of Columbia\", len(dfcovCnty_current[dfcovCnty_current.state == \"District of Columbia\"]), \"rows in the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty = dfcovCnty.drop(dfcovCnty[dfcovCnty.state == \"Puerto Rico\"].index)\n",
    "dfcovCnty_current = dfcovCnty[dfcovCnty.date == '2021-07-30']\n",
    "dfcovCnty.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now, the number of rows in the dataset is equal to the number of unique values in column 'fips':\", \n",
    "      len(dfcovCnty_current) == dfcovCnty_current.fips.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of rows of the dataframe is equal to the number of unique values for variable \"fips\". We can consider the column \"fips\" as the key of the dataframe. That is, each row in dataframe current represents a different US county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the county data, we also aggregated the cumulative cases and deaths by state level to replicate the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovSt = pd.DataFrame(dfcovCnty.groupby([\"state\", \"date\"])[[\"cases\", \"deaths\"]].sum())\n",
    "dfcovSt.reset_index(inplace=True)\n",
    "dfcovSt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovSt_current = dfcovSt[dfcovSt.date == \"2021-07-30\"]\n",
    "dfcovSt_current.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Vaccination Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac = pd.read_csv(\"data/us_state_vaccinations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vaccine dataset has\", dfvac.shape[0], \"rows and\", dfvac.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset contains the time series state level data of US vaccination, we subsetted the current date as an example to examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current = dfvac[dfvac.date == '2021-07-30']\n",
    "dfvac_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the unique locations, we will only be keeping the states and the capital city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current.location.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only location where it is a state will be kept, and also we need to change New York State to New York in order to match with other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current = dfvac_current[~dfvac_current.location.isin(['American Samoa','Bureau of Prisons','Dept of Defense','Federated States of Micronesia',\n",
    "               'Indian Health Svc','Long Term Care','Marshall Islands','Northern Mariana Islands',\n",
    "               'Puerto Rico', 'Republic of Palau','United States','Veterans Health','Guam','Virgin Islands'])]\n",
    "dfvac_current[dfvac_current.location == \"New York State\"] = \"New York\"\n",
    "dfvac_current.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we removed those locations from the time series dataframe as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac = dfvac[~dfvac.location.isin(['American Samoa','Bureau of Prisons','Dept of Defense','Federated States of Micronesia',\n",
    "               'Indian Health Svc','Long Term Care','Marshall Islands','Northern Mariana Islands',\n",
    "               'Puerto Rico', 'Republic of Palau','United States','Veterans Health','Guam','Virgin Islands'])]\n",
    "dfvac[dfvac.location == \"New York State\"] = \"New York\"\n",
    "dfvac.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking for missing values again. We do not have missing values anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have the 50 states and the capital city in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now, the number of rows in the dataset is equal to the number of unique values in column 'location':\", \n",
    "      len(dfvac_current) == dfvac_current.location.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of rows of the dataframe is equal to the number of unique values for variable \"location\". We can consider the column \"location\" as the key column of the dataframe. That is, each row in dataframe current represents a different US county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge county-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the current county-level data\n",
    "Merge County info with covid cases by county (current only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCounty = pd.merge(dfCounty, dfcovCnty_current, how='inner', on='fips', validate = \"1:1\")\n",
    "mergeCounty.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the above with poverty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov = pd.merge(mergeCounty, dfPoverty, how='inner', left_on='fips', right_on='FIPStxt', validate = \"1:1\")\n",
    "mergeCouPov.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we checked the missing values and found out that the missing values occur due to the fact that District of Columbia does not have a state code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov[mergeCouPov.state_code_x.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov[mergeCouPov.state_code_y.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we removed some of the redundant columns and kept the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_current = mergeCouPov[['fips', 'county_x', 'state_x', 'state_code_x', 'male', 'female',\n",
    "       'median_age', 'population', 'female_percentage', 'lat_x', 'long_x', 'date', 'cases',\n",
    "       'deaths', 'Rural-urban_Continuum_Code_2013', 'Urban_Influence_Code_2013',\n",
    "       'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_current.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge time series county-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCountyts = pd.merge(dfCounty, dfcovCnty, how='inner', on='fips', validate = \"1:m\")\n",
    "mergeCountyts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts = pd.merge(mergeCountyts, dfPoverty, how='inner', left_on='fips', right_on='FIPStxt', validate = \"m:1\")\n",
    "mergeCouPovts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts[mergeCouPovts.state_code_x.isnull()].county_x.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts[mergeCouPovts.state_code_y.isnull()].county_x.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the missing values here are also due to District of Columbia not having a state code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ts = mergeCouPovts[['fips', 'county_x', 'state_x', 'state_code_x', 'male', 'female',\n",
    "       'median_age', 'population', 'female_percentage', 'lat_x', 'long_x', 'date', 'cases',\n",
    "       'deaths', 'Rural-urban_Continuum_Code_2013', 'Urban_Influence_Code_2013',\n",
    "       'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge state-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge current state-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState = pd.merge(dfcovSt_current, state_pop, how='inner', on = 'state')\n",
    "mergeCovState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePov = pd.merge(mergeCovState, dfPoverty, how = \"inner\", left_on = \"state\", right_on = \"Area_name\")\n",
    "mergeCovStatePov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that there are two observations of District of Columbia, thus we removed the second one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePov.drop(mergeCovStatePov[mergeCovStatePov.FIPStxt == 11001].index, inplace = True)\n",
    "len(mergeCovStatePov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovVac = pd.merge(mergeCovStatePov, dfvac_current, how = \"inner\", left_on = \"state\", right_on = \"location\")\n",
    "mergeCovStatePovVac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovVac.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_current = mergeCovStatePovVac[['state', 'date_x', 'cases', 'deaths', 'male', 'female', 'population',\n",
    "       'female_proportion', 'FIPStxt', 'Stabr', 'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018', 'total_vaccinations', 'total_distributed', 'people_vaccinated', \n",
    "       'people_fully_vaccinated_per_hundred', 'total_vaccinations_per_hundred',\n",
    "       'people_fully_vaccinated', 'people_vaccinated_per_hundred',\n",
    "       'distributed_per_hundred', 'daily_vaccinations_raw',\n",
    "       'daily_vaccinations', 'daily_vaccinations_per_million',\n",
    "       'share_doses_used']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statelonlat = pd.read_csv('data/StateLonLat.csv')\n",
    "statelonlat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState2 = pd.merge(mergeCovState, statelonlat, how='left', on = 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for str in  mergeCovState2['date']:\n",
    "    lis.append(int(str[-1]))\n",
    "    \n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState2[\"daylastdigit\"] = lis\n",
    "mergeCovState10days = mergeCovState2[mergeCovState2[\"daylastdigit\"]== 0 ]\n",
    "mergeCovState10days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(mergeCovState10days, lon = \"longitude\", lat = \"latitude\", hover_name='state', size=\"cases\",\n",
    "               animation_frame=\"date\", projection='albers usa')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = []\n",
    "for str in  county_ts['date']:\n",
    "    lis.append(int(str[-1]))\n",
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ts[\"daylastdigit\"] = lis\n",
    "county_ts10days = county_ts[county_ts[\"daylastdigit\"] == 0 ]\n",
    "county_ts10days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(county_ts, lon = \"long_x\", lat = \"lat_x\", hover_name='county_x', size=\"cases\",\n",
    "               animation_frame=\"date\", projection='albers usa', color = \"Rural-urban_Continuum_Code_2013\")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        traceorder=\"reversed\",\n",
    "        title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            family=\"Courier\",\n",
    "            size=9,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor=\"LightSteelBlue\",\n",
    "        bordercolor=\"Black\",\n",
    "        borderwidth=2\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
