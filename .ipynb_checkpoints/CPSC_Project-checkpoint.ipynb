{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPSC4810 Data Wrangling Project\n",
    "#### Leo Liang\n",
    "#### Qirui Cao\n",
    "#### Latesh Subramanayam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Project objectives and description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(Data sources:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.colors as mcol\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Section 1 Data Inspection and Cleaning\n",
    "\n",
    "(description data sources for each dataset:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the county data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfCounty = pd.read_csv(\"data/us_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfCounty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"County dataset has\", dfCounty.shape[0], \"rows and\", dfCounty.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The number of rows in the dataset is equal to the number of unique values in column 'fips':\", \n",
    "      len(dfCounty) == dfCounty.fips.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the number of rows of the dataframe is equal to the number of unique values for variable \"fips\". We can consider the column \"fips\" as the key of the dataframe. That is, each row in dataframe dfCounty represents a different US county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfCounty.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, by running the total number of missing values for each variable, we find out that there are 79 missing values for \"state_code\". Then we need to check those rows containing missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfCounty[dfCounty.state_code.isnull()]['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Puerto Rico has\", len(dfCounty[dfCounty.state == \"Puerto Rico\"]), \"rows in the dataframe. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"District of Columbia\", len(dfCounty[dfCounty.state == \"District of Columbia\"]), \"rows in the dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We find out that the only two states which do not have a state code are Puerto Rico and District of Columbia. By comparing the number of rows for two states, and the number of missing value occurance, we can be sure that state Puerto Rico and District of Columbia do not have state code. \n",
    "\n",
    "This is because both areas are not a US state, then they do not have a US state code. Since Puerto Rico is not part of 50 states + 1 disctrict, we exclude those observations from the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfCounty = dfCounty.drop(dfCounty[dfCounty.state == \"Puerto Rico\"].index)\n",
    "print(\"The number of unique states in the dataframe: \", dfCounty.state.nunique())\n",
    "dfCounty.state.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, we aggregate the population by all states to replicate the raw dataframe with state-level information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "state_pop = pd.DataFrame(dfCounty.groupby('state')[['male','female','population']].sum())\n",
    "state_pop[\"female_proportion\"] = state_pop.female/state_pop.population\n",
    "state_pop.reset_index(level=0, inplace=True)\n",
    "state_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect the Poverty data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty = pd.read_csv(\"data/PovertyEstimates_us_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, we altered the dataset to keep the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty = dfPoverty[['FIPStxt', 'Stabr', 'Area_name', 'Rural-urban_Continuum_Code_2013', 'Urban_Influence_Code_2013', \n",
    "                        'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018', 'MEDHHINC_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Poverty dataset has\", dfPoverty.shape[0], \"rows and\", dfPoverty.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The number of rows in the dataset is equal to the number of unique values in column 'fips':\", \n",
    "      len(dfPoverty) == dfPoverty[\"FIPStxt\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly, since the number of rows of the dataframe is equal to the number of unique values for variable \"FIPStxt\". We can consider the column \"FIPStxt\" as the key of the dataframe. That is, each row in dataframe dfCounty represents a different US area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, by running the total number of missing values for each variable, we find out that there are 52 missing values for 2013's \"RUCC\" and \"UIC\". Then we need to check those rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty[dfPoverty[\"Rural-urban_Continuum_Code_2013\"].isna()][\"Area_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty[dfPoverty[\"Urban_Influence_Code_2013\"].isna()][\"Area_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By observing the missing values in both columns, the corresponding area names are states and US itself. The missing values are due to the fact that the country US itself and states are not applied to the county-level code, as it only applies to counties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Meanwhile, Rural-urban Continuum Code 2013 and Urban Influence Code 2013 are all categorical variables, which have their corresponding categories. (Please see documents below) Then, we need to map the code to their corresponding description. \n",
    "\n",
    "Rural-Urban Continuum Code: https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/documentation/\n",
    "Urban Influence Code: https://www.ers.usda.gov/data-products/urban-influence-codes/documentation.aspx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "im1 = Image.open(\"data/RUCC.png\") \n",
    "im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "im2 = Image.open(\"data/UIC.png\") \n",
    "im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "RUCC = {1: \"Level 1\", \n",
    "           2: \"Level 2\",\n",
    "           3: \"Level 3\",\n",
    "           4: \"Level 4\",\n",
    "           5: \"Level 5\",\n",
    "           6: \"Level 6\", \n",
    "           7: \"Level 7\", \n",
    "           8: \"Level 8\",\n",
    "           9: \"Level 9\"\n",
    "          }\n",
    "\n",
    "UIC = {1: \"Level 1\",\n",
    "       2: \"Level 2\",\n",
    "       3: \"Level 3\",\n",
    "       4: \"Level 4\",\n",
    "       5: \"Level 5\",\n",
    "       6: \"Level 6\",\n",
    "       7: \"Level 7\",\n",
    "       8: \"Level 8\",\n",
    "       9: \"Level 9\",\n",
    "       10: \"Level 10\",\n",
    "       11: \"Level 11\",\n",
    "       12: \"Level 12\",\n",
    "       }\n",
    "\n",
    "dfPoverty[\"Rural-urban_Continuum_Code_2013\"] = dfPoverty[\"Rural-urban_Continuum_Code_2013\"].map(RUCC)\n",
    "dfPoverty[\"Urban_Influence_Code_2013\"] = dfPoverty[\"Urban_Influence_Code_2013\"].map(UIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dfPoverty.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect COVID case and death data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty = pd.read_csv(\"data/covid_us_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"COVID dataset has\", dfcovCnty.shape[0], \"rows and\", dfcovCnty.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data contains the county-level cumulative cases and deaths starting from January 22nd, 2020. Let's take the current date, and inspect the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current = dfcovCnty[dfcovCnty['date'] == '2021-07-30']\n",
    "dfcovCnty_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"current date COVID dataset has\", dfcovCnty_current.shape[0], \"rows and\", dfcovCnty_current.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 missing values in column \"fips\", 6 in column \"county\" and 89 in column \"state_code\". We need to check all the rows containing these missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current[dfcovCnty_current.fips.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the merging stage of our project, we will merge by fips, which is the key column for most of our county-level dataframe, we will remove those rows containing missing values in fips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current[dfcovCnty_current.county.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the missing values in county indicates two cruise ships and four areas outside 50 states + 1 district, we remove those rows as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty=dfcovCnty.dropna(subset=['fips','county'])\n",
    "dfcovCnty_current=dfcovCnty_current.dropna(subset=['fips','county'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we checked the rows with missing state codes, and found out that only Puerto Rico and District of Columbia don't have state code. It is the same case as the previous situation where both areas are not a US state, thus there are no state codes. And we removed rows with Puerto Rico as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current[dfcovCnty_current.state_code.isnull()].state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Puerto Rico has\", len(dfcovCnty_current[dfcovCnty_current.state == \"Puerto Rico\"]), \"rows in the dataframe. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"District of Columbia\", len(dfcovCnty_current[dfcovCnty_current.state == \"District of Columbia\"]), \"rows in the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty = dfcovCnty.drop(dfcovCnty[dfcovCnty.state == \"Puerto Rico\"].index)\n",
    "dfcovCnty_current = dfcovCnty[dfcovCnty.date == '2021-07-30']\n",
    "print(\"The number of unique states in the original dataset is:\", dfcovCnty.state.nunique())\n",
    "dfcovCnty.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty[dfcovCnty.state_code.isnull()].state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now, the number of rows in the dataset is equal to the number of unique values in column 'fips':\", \n",
    "      len(dfcovCnty_current) == dfcovCnty_current.fips.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of rows of the dataframe is equal to the number of unique values for variable \"fips\". We can consider the column \"fips\" as the key of the dataframe. That is, each row in dataframe current represents a different US county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovCnty_current.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the county data, we also aggregated the cumulative cases and deaths by state level to replicate the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovSt = pd.DataFrame(dfcovCnty.groupby([\"state\", \"date\"])[[\"cases\", \"deaths\"]].sum())\n",
    "dfcovSt.reset_index(inplace=True)\n",
    "dfcovSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcovSt_current = dfcovSt[dfcovSt.date == \"2021-07-30\"]\n",
    "dfcovSt_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Vaccination Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac = pd.read_csv(\"data/us_state_vaccinations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vaccine dataset has\", dfvac.shape[0], \"rows and\", dfvac.shape[1], \"columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset contains the time series state level data of US vaccination, we subsetted the current date as an example to examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current = dfvac[dfvac.date == '2021-07-30']\n",
    "dfvac_current.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the unique locations, we will only be keeping the states and the capital city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current.location.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only location where it is a state will be kept, and also we need to change New York State to New York in order to match with other datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current = dfvac_current[~dfvac_current.location.isin(['American Samoa','Bureau of Prisons','Dept of Defense','Federated States of Micronesia',\n",
    "               'Indian Health Svc','Long Term Care','Marshall Islands','Northern Mariana Islands',\n",
    "               'Puerto Rico', 'Republic of Palau','United States','Veterans Health','Guam','Virgin Islands'])]\n",
    "dfvac_current.location[dfvac_current.location == \"New York State\"] = \"New York\"\n",
    "dfvac_current.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we removed those locations from the time series dataframe as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac = dfvac[~dfvac.location.isin(['American Samoa','Bureau of Prisons','Dept of Defense','Federated States of Micronesia',\n",
    "               'Indian Health Svc','Long Term Care','Marshall Islands','Northern Mariana Islands',\n",
    "               'Puerto Rico', 'Republic of Palau','United States','Veterans Health','Guam','Virgin Islands'])]\n",
    "dfvac.location[dfvac.location == \"New York State\"] = \"New York\"\n",
    "dfvac.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking for missing values again. We do not have missing values anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have the 50 states and the capital city in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now, the number of rows in the dataset is equal to the number of unique values in column 'location':\", \n",
    "      len(dfvac_current) == dfvac_current.location.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of rows of the dataframe is equal to the number of unique values for variable \"location\". We can consider the column \"location\" as the key column of the dataframe. That is, each row in dataframe current represents a different US county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac = dfvac[['date', 'location', 'people_vaccinated', 'people_fully_vaccinated_per_hundred',\n",
    "       'total_vaccinations_per_hundred', 'people_fully_vaccinated',\n",
    "       'people_vaccinated_per_hundred', 'daily_vaccinations',\n",
    "       'daily_vaccinations_per_million']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvac_current = dfvac_current[['date', 'location', 'people_vaccinated', 'people_fully_vaccinated_per_hundred',\n",
    "       'total_vaccinations_per_hundred', 'people_fully_vaccinated',\n",
    "       'people_vaccinated_per_hundred', 'daily_vaccinations',\n",
    "       'daily_vaccinations_per_million']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we included the relevant columns for merging and visualizing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Merge county-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the current county-level data\n",
    "Merge County info with covid cases by county (current only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCounty = pd.merge(dfCounty, dfcovCnty_current, how='inner', on='fips', validate = \"1:1\")\n",
    "mergeCounty.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the above with poverty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov = pd.merge(mergeCounty, dfPoverty, how='inner', left_on='fips', right_on='FIPStxt', validate = \"1:1\")\n",
    "mergeCouPov.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we checked the missing values and found out that the missing values occur due to the fact that District of Columbia does not have a state code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov[mergeCouPov.state_code_x.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPov[mergeCouPov.state_code_y.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we removed some of the redundant columns and kept the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_current = mergeCouPov[['fips', 'county_x', 'state_x', 'state_code_x', 'male', 'female',\n",
    "       'median_age', 'population', 'female_percentage', 'lat_x', 'long_x', 'date', 'cases',\n",
    "       'deaths', 'Rural-urban_Continuum_Code_2013', 'Urban_Influence_Code_2013',\n",
    "       'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_current.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge time series county-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCountyts = pd.merge(dfCounty, dfcovCnty, how='inner', on='fips', validate = \"1:m\")\n",
    "mergeCountyts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts = pd.merge(mergeCountyts, dfPoverty, how='inner', left_on='fips', right_on='FIPStxt', validate = \"m:1\")\n",
    "mergeCouPovts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts[mergeCouPovts.state_code_x.isnull()].county_x.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCouPovts[mergeCouPovts.state_code_y.isnull()].county_x.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the missing values here are also due to District of Columbia not having a state code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ts = mergeCouPovts[['fips', 'county_x', 'state_x', 'state_code_x', 'male', 'female',\n",
    "       'median_age', 'population', 'female_percentage', 'lat_x', 'long_x', 'date', 'cases',\n",
    "       'deaths', 'Rural-urban_Continuum_Code_2013', 'Urban_Influence_Code_2013',\n",
    "       'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we removed the redundant columns like the current data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge state-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge current state-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState = pd.merge(dfcovSt_current, state_pop, how='inner', on = 'state')\n",
    "mergeCovState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePov = pd.merge(mergeCovState, dfPoverty, how = \"inner\", left_on = \"state\", right_on = \"Area_name\")\n",
    "mergeCovStatePov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out that there are two observations of District of Columbia, thus we removed the second one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePov.drop(mergeCovStatePov[mergeCovStatePov.FIPStxt == 11001].index, inplace = True)\n",
    "mergeCovStatePov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovVac = pd.merge(mergeCovStatePov, dfvac_current, how = \"left\", left_on = \"state\", right_on = \"location\")\n",
    "mergeCovStatePovVac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovVac.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we removed redundant columns and removed the RUCC and UIC which are only applied to counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_current = mergeCovStatePovVac[['state', 'date_x', 'cases', 'deaths', 'male', 'female', 'population',\n",
    "       'female_proportion', 'FIPStxt', 'Stabr', \n",
    "       'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018', 'people_vaccinated', 'people_fully_vaccinated_per_hundred', 'total_vaccinations_per_hundred',\n",
    "       'people_fully_vaccinated', 'people_vaccinated_per_hundred',\n",
    "       'daily_vaccinations', 'daily_vaccinations_per_million']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_current.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge time series state-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatets = pd.merge(dfcovSt, state_pop, how='inner', on = 'state')\n",
    "mergeCovStatets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovts = pd.merge(mergeCovStatets, dfPoverty, how = \"inner\", left_on = \"state\", right_on = \"Area_name\")\n",
    "mergeCovStatePovts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovts.drop(mergeCovStatePovts[mergeCovStatePovts.FIPStxt == 11001].index, inplace = True)\n",
    "mergeCovStatePovts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we applied the left join, as the date of the previous dataframe ranges from Jan 2020 to current date, while the vaccination data includes from Jan 2021. We need to keep the cases/deaths data before Jan 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovVacts = pd.merge(mergeCovStatePovts, dfvac, how = \"left\", left_on = [\"state\", \"date\"], right_on = [\"location\", \"date\"])\n",
    "mergeCovStatePovVacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovStatePovVacts.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the missing values in the vaccination data, we choose to backfill the missing values to avoid potential breaks in the plots. Also, we removed redundant columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ts = mergeCovStatePovVacts[['state', 'date', 'cases', 'deaths', 'male', 'female', 'population',\n",
    "       'female_proportion', 'FIPStxt', 'Stabr', \n",
    "       'POVALL_2018', 'PCTPOVALL_2018', 'POV017_2018', 'PCTPOV017_2018',\n",
    "       'MEDHHINC_2018', 'people_vaccinated', 'people_fully_vaccinated_per_hundred', 'total_vaccinations_per_hundred',\n",
    "       'people_fully_vaccinated', 'people_vaccinated_per_hundred',\n",
    "       'daily_vaccinations', 'daily_vaccinations_per_million']]\n",
    "state_ts.fillna(method = \"bfill\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Plot\n",
    "### National level Cases, Deaths, Vaccination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we aggregate the state level time series data by dates to derive the national level data by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_ts = pd.DataFrame(state_ts.groupby('date')[['cases', 'deaths', 'people_fully_vaccinated', 'people_vaccinated']].sum())\n",
    "nation_ts.reset_index(inplace = True)\n",
    "nation_ts.fillna(method = \"bfill\", inplace = True)\n",
    "nation_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we subsetted the dataframe and derive the daily cases by differentiate the cumulative data. (also we smoothed out the cases and deaths for better visualization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natCaseDeath = nation_ts\n",
    "natCaseDeath[['cases', 'deaths', 'people_fully_vaccinated', 'people_vaccinated']] = natCaseDeath[['cases', 'deaths', 'people_fully_vaccinated', 'people_vaccinated']].rolling(7).mean()\n",
    "natCaseDeath.date = pd.to_datetime(natCaseDeath.date)\n",
    "natCaseDeathDay = natCaseDeath.diff()\n",
    "natCaseDeathDay['date'] = natCaseDeath['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plt.title(\"US national cumulative COVID cases, death and fully vaccinated since 2020-01-22\")\n",
    "sns.lineplot(data = natCaseDeath, x = \"date\", y = 'cases', palette=\"tab10\", linewidth=2.5, label = 'cases')\n",
    "sns.lineplot(data = natCaseDeath, x = \"date\", y = 'deaths', palette=\"tab10\", linewidth=2.5, label = 'deaths')\n",
    "sns.lineplot(data = natCaseDeath, x = \"date\", y = 'people_fully_vaccinated', palette=\"tab10\", linewidth=2.5, label = 'people fully vaccinated')\n",
    "sns.lineplot(data = natCaseDeath, x = \"date\", y = 'people_vaccinated', palette=\"tab10\", linewidth=2.5, label = 'people vaccinated')\n",
    "plt.grid(True)\n",
    "ax.set(xlabel=\"Date\", ylabel=\"Cumulative Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big increase in cases prior to intro of vaccines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plt.title(\"US national daily COVID cases, deaths and fully vaccinated since 2020-01-22\")\n",
    "sns.lineplot(data = natCaseDeathDay, x = \"date\", y = 'cases', palette=\"tab10\", linewidth=2.5, label = 'cases')\n",
    "sns.lineplot(data = natCaseDeathDay, x = \"date\", y = 'deaths', palette=\"tab10\", linewidth=2.5, label = 'deaths')\n",
    "sns.lineplot(data = natCaseDeathDay, x = \"date\", y = 'people_fully_vaccinated', palette=\"tab10\", linewidth=2.5, label = 'people fully vaccinated')\n",
    "sns.lineplot(data = natCaseDeathDay, x = \"date\", y = 'people_vaccinated', palette=\"tab10\", linewidth=2.5, label = 'people vaccinated')\n",
    "plt.grid(True)\n",
    "ax.set(xlabel=\"Date\", ylabel=\"Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro of vaccine drastically decrease daily cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_cumulative_ts = pd.DataFrame(state_ts.groupby('date')[['cases', 'deaths', 'people_fully_vaccinated', 'people_vaccinated']].sum())\n",
    "nation_daily_ts = nation_cumulative_ts.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ts.loc[:,'casePer100'] = state_ts.cases/state_ts.population*100\n",
    "state_ts.loc[:,'vacPer100'] = state_ts.people_fully_vaccinated/state_ts.population*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ts_curr = state_ts[state_ts.date == \"2021-07-30\"]\n",
    "state_ts_curr_sorted = state_ts_curr.sort_values('casePer100')\n",
    "x = state_ts_curr_sorted.state\n",
    "y = state_ts_curr_sorted.casePer100\n",
    "z = state_ts_curr.vacPer100\n",
    "\n",
    "my_cmap = plt.get_cmap(\"flag\")\n",
    "rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.grid(True)\n",
    "plt.barh(x, y, align='center', color = my_cmap(rescale(y)))\n",
    "plt.xlabel('Cases per 100', fontsize = 15)\n",
    "plt.title('Cases per 100 in each state 2021-07-30', fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "North Dakota currently has highest cases per 100 which is 5 times that of Hawaii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_ts_curr_sorted = state_ts_curr.sort_values('vacPer100')\n",
    "x = state_ts_curr_sorted.state\n",
    "y = state_ts_curr_sorted.vacPer100\n",
    "\n",
    "my_cmap = plt.get_cmap(\"flag\")\n",
    "rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.grid(True)\n",
    "plt.barh(x, y, align='center', color = my_cmap(rescale(y)))\n",
    "plt.xlabel('Fully Vaccinated per 100', fontsize = 15)\n",
    "plt.title('Fully Vaccinated per 100 in each state 2021-07-30', fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "North-Eastern Us has relatively higher proportion of residents fully vaccinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12,6))\n",
    "#groups = state_ts[state_ts.state == 'North Dakota'].groupby('state')\n",
    "#for name, group in groups:\n",
    "#    plt.plot(group.date, group.casePer100, linestyle='-', markersize=5, label=name, alpha = 0.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_current.loc[:,'cases100'] = county_current.loc[:,\"cases\"]/county_current.loc[:,\"population\"]*100\n",
    "county_current.loc[:,'deaths100'] = county_current.loc[:,\"deaths\"]/county_current.loc[:,\"population\"]*100\n",
    "county_current.loc[:,'deathratio'] = county_current.loc[:,\"deaths\"]/county_current.loc[:,\"cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metro = {\"Level 1\": \"Metro\", \n",
    "         \"Level 2\": \"Metro\",\n",
    "         \"Level 3\": \"Metro\",\n",
    "         \"Level 4\": \"Adjacent to Metro\",\n",
    "         \"Level 5\": \"Not adjacent to metro\",\n",
    "         \"Level 6\": \"Adjacent to Metro\", \n",
    "         \"Level 7\": \"Not adjacent to metro\",\n",
    "         \"Level 8\": \"Adjacent to Metro\",\n",
    "         \"Level 9\": \"Not adjacent to metro\"\n",
    "          }\n",
    "\n",
    "county_current[\"Metro\"] = county_current[\"Rural-urban_Continuum_Code_2013\"].map(Metro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Plot of Median Household Income vs COVID Deaths (per 100) at county level\", fontsize = 15)\n",
    "plt.xlabel(\"Median Household Income\", fontsize = 15)\n",
    "plt.ylabel(\"COVID Deaths (per 100)\", fontsize = 15)\n",
    "plt.grid(True)\n",
    "colors = {'Metro':'k', 'Adjacent to Metro':'c', 'Not adjacent to metro':'r'}\n",
    "groups = county_current.groupby('Metro')\n",
    "for name, group in groups:\n",
    "    plt.plot(group.MEDHHINC_2018, group.deaths100, color = colors[name], marker='o', linestyle='', markersize=5, label=name, alpha = 0.5)\n",
    "    plt.plot(group.MEDHHINC_2018, np.poly1d(np.polyfit(group.MEDHHINC_2018, group.deaths100, 1))(group.MEDHHINC_2018), \n",
    "             color = colors[name], alpha = 1, linewidth=3)\n",
    "    plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties with lower median household income may have less sophisticated medical facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statelonlat = pd.read_csv('data/StateLonLat.csv')\n",
    "statelonlat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState2 = pd.merge(state_ts, statelonlat, how='left', on = 'state')\n",
    "mergeCovState2['deathPer100'] = mergeCovState2.deaths/mergeCovState2.population*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState2[\"daylastdigit\"] = mergeCovState2['date'].apply(lambda x: (x[-1] == \"0\")|(x[-1] == \"5\"))\n",
    "mergeCovState5days = mergeCovState2[mergeCovState2[\"daylastdigit\"]]\n",
    "mergeCovState5days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeCovState5days.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(mergeCovState10days, lon = \"longitude\", lat = \"latitude\", hover_name='state', size=\"casePer100\",\n",
    "               animation_frame=\"date\", projection='albers usa')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(mergeCovState10days, lon = \"longitude\", lat = \"latitude\", hover_name='state', size=\"deathPer100\",\n",
    "               animation_frame=\"date\", projection='albers usa')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ts[\"daylastdigit\"] = county_ts['date'].apply(lambda x: (x[-1] == \"0\") | (x[-1] == \"5\") )\n",
    "county_ts['casePer100'] = county_ts.cases/county_ts.population*100\n",
    "county_ts['deathPer100'] = county_ts.deaths/county_ts.population*100\n",
    "county_ts5days = county_ts[county_ts[\"daylastdigit\"]]\n",
    "county_ts5days.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(county_ts5days, lon = \"long_x\", lat = \"lat_x\", hover_name='county_x', size=\"casePer100\",\n",
    "               animation_frame=\"date\", projection='albers usa', color = \"Rural-urban_Continuum_Code_2013\")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        traceorder=\"reversed\",\n",
    "        title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            family=\"Courier\",\n",
    "            size=9,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor=\"LightSteelBlue\",\n",
    "        bordercolor=\"Black\",\n",
    "        borderwidth=2\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandemic first breakout in metro areas on the Eastern and southern part of US. Then, it starts spreading to non-metro areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(county_ts5days, lon = \"long_x\", lat = \"lat_x\", hover_name='county_x', size=\"deathPer100\",\n",
    "               animation_frame=\"date\", projection='albers usa', color = \"Rural-urban_Continuum_Code_2013\")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        traceorder=\"reversed\",\n",
    "        title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            family=\"Courier\",\n",
    "            size=9,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor=\"LightSteelBlue\",\n",
    "        bordercolor=\"Black\",\n",
    "        borderwidth=2\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
